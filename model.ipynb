{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - C5i Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Yaxh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import math\n",
    "from nltk.corpus import words\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Datatset loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "First 5 rows of the dataset:\n",
      "   Unique ID          Start Date            End Date  \\\n",
      "0        NaN                 NaT                 NaT   \n",
      "1        3.0 2024-10-11 09:43:37 2024-10-11 09:53:40   \n",
      "2        5.0 2024-10-11 09:42:41 2024-10-11 09:55:49   \n",
      "3        6.0 2024-10-11 09:46:20 2024-10-11 09:56:42   \n",
      "4        8.0 2024-10-11 09:47:15 2024-10-11 09:57:19   \n",
      "\n",
      "   Q1. What is your current age? \\n(Age)  Q2. What is your gender? \\n(Gender)  \\\n",
      "0                                    NaN                                  NaN   \n",
      "1                                   60.0                                  2.0   \n",
      "2                                   61.0                                  1.0   \n",
      "3                                   58.0                                  1.0   \n",
      "4                                   55.0                                  1.0   \n",
      "\n",
      "   Q3. Which of the following best describes the area or community in which you live? \\n(Urban/Rural)  \\\n",
      "0                                                NaN                                                    \n",
      "1                                                3.0                                                    \n",
      "2                                                3.0                                                    \n",
      "3                                                1.0                                                    \n",
      "4                                                3.0                                                    \n",
      "\n",
      "   Q4.  Please indicate the answer that includes your entire household income in (previous year) before taxes. \\n(Income)  \\\n",
      "0                                                NaN                                                                        \n",
      "1                                               12.0                                                                        \n",
      "2                                                3.0                                                                        \n",
      "3                                                8.0                                                                        \n",
      "4                                               11.0                                                                        \n",
      "\n",
      "  Q6 Which of the following types of alcoholic beverages have you consumed in the past 4 weeks?\\n(Alcohol Category)  \\\n",
      "0                                               Beer                                                                  \n",
      "1                                                  1                                                                  \n",
      "2                                                  1                                                                  \n",
      "3                                                  1                                                                  \n",
      "4                                                  1                                                                  \n",
      "\n",
      "             Unnamed: 8            Unnamed: 9  ...  \\\n",
      "0   Flavored/Mixed Beer   Non-Alcoholic Beers  ...   \n",
      "1                     0                     0  ...   \n",
      "2                     0                     0  ...   \n",
      "3                     0                     0  ...   \n",
      "4                     0                     0  ...   \n",
      "\n",
      "  Q13. How does the price fit with what youâ€™d expect the shown to cost?\\n(Concept_Price)  \\\n",
      "0                                                NaN                                       \n",
      "1                                                3.0                                       \n",
      "2                                                3.0                                       \n",
      "3                                                3.0                                       \n",
      "4                                                3.0                                       \n",
      "\n",
      "  Q14. Which statement below best describes how likely you would be to buy shown product if it were available at your local stores?\\n(Concept_Purchase Intent)  \\\n",
      "0                                                NaN                                                                                                             \n",
      "1                                                2.0                                                                                                             \n",
      "2                                                5.0                                                                                                             \n",
      "3                                                1.0                                                                                                             \n",
      "4                                                5.0                                                                                                             \n",
      "\n",
      "  Q15. If the shwon product was available to you, how often would you expect yourself to drink at least one of these products?\\n(Concept_Drinking Frequency)  \\\n",
      "0                                                NaN                                                                                                           \n",
      "1                                                2.0                                                                                                           \n",
      "2                                                4.0                                                                                                           \n",
      "3                                                0.0                                                                                                           \n",
      "4                                                7.0                                                                                                           \n",
      "\n",
      "  Q16A. What is the most important thing you LIKE about the shown concept}?     This can include anything you would want kept for sure or aspects that might drive you to buy or try itâ€¦       Please type a detailed response in the space below  \\\n",
      "0                                                NaN                                                                                                                                                                                                \n",
      "1                                      the packaging                                                                                                                                                                                                \n",
      "2                     It's a good and trusted brand.                                                                                                                                                                                                \n",
      "3                       Just that it is a lager beer                                                                                                                                                                                                \n",
      "4                          has a less filling effect                                                                                                                                                                                                \n",
      "\n",
      "  Q16B. What is the most important thing you DISLIKE about the shown concept}?    This can include general concerns, annoyances, or any aspects of the product that need fixed for this to be more appealing to you...     Please type a detailed response in the space below.  \\\n",
      "0                                                NaN                                                                                                                                                                                                                             \n",
      "1                                            nothing                                                                                                                                                                                                                             \n",
      "2                       It's seem some what generic.                                                                                                                                                                                                                             \n",
      "3  I don't like Anheiser Busch and their values a...                                                                                                                                                                                                                             \n",
      "4                                         no dislike                                                                                                                                                                                                                             \n",
      "\n",
      "  Q17. We would like to know what effect this new product might have on the other beverages you buy. If it were available, would the shown productâ€¦? \\n(Concept_Replacement Product)  \\\n",
      "0                                                NaN                                                                                                                                   \n",
      "1                                                1.0                                                                                                                                   \n",
      "2                                                2.0                                                                                                                                   \n",
      "3                                                1.0                                                                                                                                   \n",
      "4                                                2.0                                                                                                                                   \n",
      "\n",
      "  Q18_1 What specific product that you are currently using would the shown product replace?\\n Please type in ONE specific brand or product per space provided.  \\\n",
      "0                                                NaN                                                                                                             \n",
      "1                                                NaN                                                                                                             \n",
      "2                                           Heineken                                                                                                             \n",
      "3                                                NaN                                                                                                             \n",
      "4                                     michelob ultra                                                                                                             \n",
      "\n",
      "  Q18_2 What specific product that you are currently using would the shown concept replace?\\n Please type in ONE specific brand or product per space provided.  \\\n",
      "0                                                NaN                                                                                                             \n",
      "1                                                NaN                                                                                                             \n",
      "2                                        Miller Lite                                                                                                             \n",
      "3                                                NaN                                                                                                             \n",
      "4                                       Miller light                                                                                                             \n",
      "\n",
      "  Q18_3 What specific product that you are currently using would the shown concept replace?\\n Please type in ONE specific brand or product per space provided.  \\\n",
      "0                                                NaN                                                                                                             \n",
      "1                                                NaN                                                                                                             \n",
      "2                                          Budwieser                                                                                                             \n",
      "3                                                NaN                                                                                                             \n",
      "4                                             corona                                                                                                             \n",
      "\n",
      "  OE_Quality_Flag  \n",
      "0             NaN  \n",
      "1             0.0  \n",
      "2             0.0  \n",
      "3             0.0  \n",
      "4             0.0  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(r\"Final Data File_Training.xlsx\", sheet_name=1)\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Gibberish Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yaxh\\AppData\\Local\\Temp\\ipykernel_17076\\2800129156.py:50: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df['Gibberish_Flag'] = df.iloc[:, oe_columns].apply(lambda row: max(is_gibberish(row[0]), is_gibberish(row[1])), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved successfully with 'Gibberish_Flag' column at the end.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load English words\n",
    "english_words = set(words.words())\n",
    "\n",
    "def is_gibberish(text, entropy_threshold=3.46, keyboard_seq_length=4, min_valid_word_ratio=0.3):\n",
    "    \"\"\"Detect gibberish text based on entropy, keyboard patterns, and valid word ratio.\"\"\"\n",
    "    \n",
    "    if pd.isna(text) or len(str(text).strip()) < 4:\n",
    "        return 0  # Not gibberish if empty or too short\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    clean_text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    if len(clean_text.strip()) < 3:\n",
    "        return 0  # Not gibberish if it's too short after cleaning\n",
    "\n",
    "    tokens = clean_text.split()\n",
    "    valid_words = sum(1 for word in tokens if word in english_words)\n",
    "    word_ratio = valid_words / len(tokens) if tokens else 0\n",
    "\n",
    "    if word_ratio >= min_valid_word_ratio:\n",
    "        return 0  # Not gibberish if enough words are valid\n",
    "\n",
    "    # Character entropy calculation\n",
    "    char_counts = Counter(text)\n",
    "    text_length = len(text)\n",
    "    entropy = -sum((count/text_length) * math.log2(count/text_length) for count in char_counts.values())\n",
    "\n",
    "    # Check for keyboard sequences\n",
    "    keyboard_rows = ['qwertyuiop', 'asdfghjkl', 'zxcvbnm']\n",
    "    has_keyboard = any(\n",
    "        any(text[i:i+keyboard_seq_length] in row or text[i:i+keyboard_seq_length] in row[::-1]\n",
    "            for row in keyboard_rows)\n",
    "        for i in range(len(text) - keyboard_seq_length + 1)\n",
    "    )\n",
    "\n",
    "    # Check for repeating characters\n",
    "    has_repeats = any(c * 3 in text for c in set(text))\n",
    "\n",
    "    # Check for consecutive consonants or vowels\n",
    "    consonants = 'bcdfghjklmnpqrstvwxyz'\n",
    "    vowels = 'aeiou'\n",
    "    has_consecutive = re.search(r'[' + consonants + ']{5}|[' + vowels + ']{4}', clean_text) is not None\n",
    "\n",
    "    return 1 if (entropy > entropy_threshold or has_keyboard or has_repeats or has_consecutive) else 0\n",
    "\n",
    "\n",
    "oe_columns = [29, 30]\n",
    "\n",
    "# Apply gibberish detection and add a new column\n",
    "df['Gibberish_Flag'] = df.iloc[:, oe_columns].apply(lambda row: max(is_gibberish(row[0]), is_gibberish(row[1])), axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a new Excel file\n",
    "df.to_excel(\"new_yay_updated.xlsx\", sheet_name=\"Sheet1\", index=False)\n",
    "\n",
    "print(\"Updated dataset saved successfully with 'Gibberish_Flag' column at the end.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - OffTopic Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yaxh\\AppData\\Local\\Temp\\ipykernel_17076\\3743088491.py:55: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  substring_mask = processed_col.str.contains(valid_substrings, na=False)\n",
      "C:\\Users\\Yaxh\\AppData\\Local\\Temp\\ipykernel_17076\\3743088491.py:58: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  fuzzy_mask = fuzzy_candidates.apply(rapidfuzz_match).replace({0: True, 1: False})\n",
      "C:\\Users\\Yaxh\\AppData\\Local\\Temp\\ipykernel_17076\\3743088491.py:55: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  substring_mask = processed_col.str.contains(valid_substrings, na=False)\n",
      "C:\\Users\\Yaxh\\AppData\\Local\\Temp\\ipykernel_17076\\3743088491.py:58: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  fuzzy_mask = fuzzy_candidates.apply(rapidfuzz_match).replace({0: True, 1: False})\n",
      "C:\\Users\\Yaxh\\AppData\\Local\\Temp\\ipykernel_17076\\3743088491.py:55: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  substring_mask = processed_col.str.contains(valid_substrings, na=False)\n",
      "C:\\Users\\Yaxh\\AppData\\Local\\Temp\\ipykernel_17076\\3743088491.py:58: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  fuzzy_mask = fuzzy_candidates.apply(rapidfuzz_match).replace({0: True, 1: False})\n"
     ]
    }
   ],
   "source": [
    "#### filepath: c:\\Users\\Yaxh\\Desktop\\Hackathonn\\model.ipynb\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from rapidfuzz import process, fuzz  # Faster than fuzzywuzzy\n",
    "from rapidfuzz.utils import default_process\n",
    "\n",
    "\n",
    "\n",
    "combined_df = pd.read_csv(\"combined.csv\")\n",
    "\n",
    "\n",
    "valid_entries = set()\n",
    "for _, row in combined_df.iterrows():\n",
    "    brand = str(row[\"Brand\"]).strip().lower()\n",
    "    product = str(row[\"Product\"]).strip().lower()\n",
    "    valid_entries.update([brand, product])\n",
    "valid_entries = list(valid_entries)\n",
    "\n",
    "# Create a regex pattern for substring matching\n",
    "valid_substrings = re.compile(\n",
    "    r\"\\b(\" + \"|\".join(map(re.escape, valid_entries)) + r\")\\b\", flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Vectorized preprocessing\n",
    "def preprocess_column(col):\n",
    "    return (\n",
    "        col.astype(str)\n",
    "        .str.lower()\n",
    "        .str.replace(r\"[^a-z0-9\\s]\", \" \", regex=True)\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "# Preprocess valid entries once for rapidfuzz\n",
    "preprocessed_valid = [default_process(entry) for entry in valid_entries]\n",
    "\n",
    "def rapidfuzz_match(entry):\n",
    "    processed_entry = default_process(entry)\n",
    "    # First check exact match\n",
    "    if processed_entry in preprocessed_valid:\n",
    "        return 0\n",
    "    # Then fuzzy match with threshold 85\n",
    "    result = process.extractOne(processed_entry, preprocessed_valid, scorer=fuzz.ratio, score_cutoff=85)\n",
    "    return 0 if result else 1\n",
    "\n",
    "# Main flagging logic (example columns 32, 33, 34)\n",
    "beer_columns = df.columns[32:35]\n",
    "\n",
    "for col in beer_columns:\n",
    "    processed_col = preprocess_column(df[col])\n",
    "    \n",
    "    # 1) Exact matches\n",
    "    exact_mask = processed_col.isin(valid_entries)\n",
    "    # 2) Substring matches\n",
    "    substring_mask = processed_col.str.contains(valid_substrings, na=False)\n",
    "    # 3) Fuzzy matches for remaining\n",
    "    fuzzy_candidates = processed_col[~(exact_mask | substring_mask)]\n",
    "    fuzzy_mask = fuzzy_candidates.apply(rapidfuzz_match).replace({0: True, 1: False})\n",
    "    \n",
    "    # Combine flags (0 = valid, 1 = flagged)\n",
    "    final_mask = exact_mask | substring_mask | fuzzy_mask\n",
    "    df[f\"{col}_flag\"] = np.where(final_mask, 0, 1)\n",
    "\n",
    "df.to_excel(\"flagged_data_optimized.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - AI detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AI detection completed! Results saved to output_with_ai_detection.csv\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Load AI detection model\n",
    "detector = pipeline(\"text-classification\", model=\"roberta-base-openai-detector\")\n",
    "\n",
    "# AI Detection Function\n",
    "def detect_ai(text):\n",
    "    if pd.isna(text) or len(text) <= 5:\n",
    "        return \"Human-Written\"\n",
    "    \n",
    "    result = detector(text)[0]\n",
    "    return \"AI-Generated\" if result['label'] == 'LABEL_1' else \"Human-Written\"\n",
    "\n",
    "# Apply detection to columns 29 and 30\n",
    "df[\"AI_Detection_29\"] = df.iloc[:, 29].apply(detect_ai)\n",
    "df[\"AI_Detection_30\"] = df.iloc[:, 30].apply(detect_ai)\n",
    "\n",
    "# Check for any AI-generated text\n",
    "if (df[\"AI_Detection_29\"] == \"AI-Generated\").any() or (df[\"AI_Detection_30\"] == \"AI-Generated\").any():\n",
    "    print(\"AI-generated text detected!\")\n",
    "\n",
    "# Save the results\n",
    "df.to_csv(\"output_with_ai_detection.csv\", index=False)\n",
    "\n",
    "print(\"âœ… AI detection completed! Results saved to output_with_ai_detection.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - S-Bert transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ **Test Accuracy: 0.9033**\n",
      "\n",
      "ðŸ”¹ **Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92       200\n",
      "           1       0.78      1.00      0.87       100\n",
      "\n",
      "    accuracy                           0.90       300\n",
      "   macro avg       0.89      0.93      0.90       300\n",
      "weighted avg       0.93      0.90      0.91       300\n",
      "\n",
      "\n",
      "âœ… **Test Results saved to 'classified_responses_sbert_balanced_test.xlsx'**\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load dataset and clean column names\n",
    "def load_data_xlsx(file_path, sheet_name=\"Data Set with Labels Text\"):\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    df.rename(columns={\n",
    "        \"Q16A. What is the most important thing you LIKE about the shown concept}?     This can include anything you would want kept for sure or aspects that might drive you to buy or try itâ€¦       Please type a detailed response in the space below\":\n",
    "            \"Q16A_Likes\",\n",
    "        \"Q16B. What is the most important thing you DISLIKE about the shown concept}?    This can include general concerns, annoyances, or any aspects of the product that need fixed for this to be more appealing to you...     Please type a detailed response in the space below.\":\n",
    "            \"Q16B_Dislikes\",\n",
    "        \"OE_Quality_Flag\": \"Quality_Flag\"\n",
    "    }, inplace=True)\n",
    "    \n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    return df\n",
    "\n",
    "# Prepare combined text feature\n",
    "def combine_texts(row):\n",
    "    # If any response is missing, fill with \"missing_text\"\n",
    "    text_a = str(row[\"Q16A_Likes\"]) if pd.notna(row[\"Q16A_Likes\"]) else \"missing_text\"\n",
    "    text_b = str(row[\"Q16B_Dislikes\"]) if pd.notna(row[\"Q16B_Dislikes\"]) else \"missing_text\"\n",
    "    return text_a + \" \" + text_b\n",
    "\n",
    "# Train classifier on combined text features using SBERT embeddings\n",
    "def train_classifier(texts, labels):\n",
    "    # Load SBERT model and encode text\n",
    "    sbert_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    embeddings = sbert_model.encode(texts)\n",
    "    \n",
    "    # Scale embeddings\n",
    "    scaler = StandardScaler()\n",
    "    embeddings_scaled = scaler.fit_transform(embeddings)\n",
    "    \n",
    "    # Train Logistic Regression with balanced class weights\n",
    "    clf = LogisticRegression(class_weight=\"balanced\", random_state=42, max_iter=1000, C=1.0)\n",
    "    clf.fit(embeddings_scaled, labels)\n",
    "    \n",
    "    return clf, scaler, sbert_model\n",
    "\n",
    "# Evaluate classifier on new texts\n",
    "def evaluate_classifier(clf, scaler, sbert_model, texts, threshold=0.5):\n",
    "    embeddings = sbert_model.encode(texts)\n",
    "    embeddings_scaled = scaler.transform(embeddings)\n",
    "    \n",
    "    # Get predicted probabilities (for class 1)\n",
    "    pred_probs = clf.predict_proba(embeddings_scaled)[:, 1]\n",
    "    predicted_labels = (pred_probs > threshold).astype(int)\n",
    "    return predicted_labels\n",
    "\n",
    "# Main function for training on full dataset, testing on balanced set\n",
    "def main(file_path, sheet_name):\n",
    "    df = load_data_xlsx(file_path, sheet_name)\n",
    "    \n",
    "    # Drop rows with missing Quality_Flag and reset index\n",
    "    df = df.dropna(subset=[\"Quality_Flag\"]).reset_index(drop=True)\n",
    "    \n",
    "    # Convert Quality_Flag to binary labels: assume 1 or '1.0' as Bad, else Good (0)\n",
    "    df[\"Quality_Flag_Binary\"] = df[\"Quality_Flag\"].apply(lambda x: 1 if x in [1, '1.0'] else 0)\n",
    "    \n",
    "    # Combine Q16A and Q16B responses into one feature\n",
    "    df[\"Combined_Text\"] = df.apply(combine_texts, axis=1)\n",
    "    \n",
    "    # Shuffle the dataset\n",
    "    df = shuffle(df, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Split dataset for training and testing\n",
    "    # Use the whole dataset for training\n",
    "    train_df = df.copy()\n",
    "\n",
    "    # Create a balanced test dataset (equal number of 0s and 1s)\n",
    "    test_good = df[df[\"Quality_Flag_Binary\"] == 0].sample(n=200, random_state=42)  \n",
    "    test_bad  = df[df[\"Quality_Flag_Binary\"] == 1].sample(n=100, random_state=42)  \n",
    "    test_df = pd.concat([test_good, test_bad]).reset_index(drop=True)\n",
    "    \n",
    "    # Train classifier on combined text from the full dataset\n",
    "    train_texts = train_df[\"Combined_Text\"].fillna(\"missing_text\").astype(str).tolist()\n",
    "    train_labels = train_df[\"Quality_Flag_Binary\"].tolist()\n",
    "    clf, scaler, sbert_model = train_classifier(train_texts, train_labels)\n",
    "    \n",
    "    # Evaluate on balanced test set\n",
    "    test_texts = test_df[\"Combined_Text\"].fillna(\"missing_text\").astype(str).tolist()\n",
    "    predicted_labels = evaluate_classifier(clf, scaler, sbert_model, test_texts, threshold=0.2)\n",
    "    \n",
    "    # Save predictions to test_df\n",
    "    test_df[\"Predicted_Values\"] = predicted_labels\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    accuracy = accuracy_score(test_df[\"Quality_Flag_Binary\"], test_df[\"Predicted_Values\"])\n",
    "    print(f\"\\nðŸ”¹ **Test Accuracy: {accuracy:.4f}**\\n\")\n",
    "    print(\"ðŸ”¹ **Classification Report:**\")\n",
    "    print(classification_report(test_df[\"Quality_Flag_Binary\"], test_df[\"Predicted_Values\"], zero_division=0))\n",
    "\n",
    "    \n",
    "    # Save test results (Quality_Flag and Predicted_Values) to Excel\n",
    "    output_df = test_df[[\"Quality_Flag\", \"Predicted_Values\"]]\n",
    "    output_file = \"classified_responses_sbert_balanced_test.xlsx\"\n",
    "    output_df.to_excel(output_file, index=False)\n",
    "    print(f\"\\n **Test Results saved to '{output_file}'**\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    xlsx_file = \"Final Data File_Training.xlsx\"\n",
    "    sheet_name = \"Data Set with Labels Text\"\n",
    "    main(xlsx_file, sheet_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ **Test Accuracy: 0.8239**\n",
      "\n",
      "ðŸ”¹ **Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       424\n",
      "           1       0.15      0.28      0.20        36\n",
      "\n",
      "    accuracy                           0.82       460\n",
      "   macro avg       0.54      0.57      0.55       460\n",
      "weighted avg       0.87      0.82      0.85       460\n",
      "\n",
      "\n",
      "ðŸ”¹ **Confusion Matrix:**\n",
      "   True Negative: 369, False Positive: 55\n",
      "   False Negative: 26, True Positive: 10\n",
      "\n",
      "ðŸ”¹ **Test Results saved to 'classifier_results_80_20_split.xlsx'**\n",
      "\n",
      "ðŸ”¹ Model saved to 'saved_model'\n",
      "\n",
      "ðŸ”¹ Predictions saved to 'Predicted_Results.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Load dataset and clean column names\n",
    "def load_data_xlsx(file_path, sheet_name=\"Data Set with Labels Text\"):\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    df.rename(columns={\n",
    "        \"Q16A. What is the most important thing you LIKE about the shown concept}?     This can include anything you would want kept for sure or aspects that might drive you to buy or try itâ€¦       Please type a detailed response in the space below\":\n",
    "            \"Q16A_Likes\",\n",
    "        \"Q16B. What is the most important thing you DISLIKE about the shown concept}?    This can include general concerns, annoyances, or any aspects of the product that need fixed for this to be more appealing to you...     Please type a detailed response in the space below.\":\n",
    "            \"Q16B_Dislikes\",\n",
    "        \"OE_Quality_Flag\": \"Quality_Flag\"\n",
    "    }, inplace=True)\n",
    "    \n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    return df\n",
    "\n",
    "# Prepare combined text feature\n",
    "def combine_texts(row):\n",
    "    text_a = str(row[\"Q16A_Likes\"]) if pd.notna(row[\"Q16A_Likes\"]) else \"missing_text\"\n",
    "    text_b = str(row[\"Q16B_Dislikes\"]) if pd.notna(row[\"Q16B_Dislikes\"]) else \"missing_text\"\n",
    "    return text_a + \" \" + text_b\n",
    "\n",
    "# Train classifier and save model\n",
    "def train_and_save_model(file_path, sheet_name, model_path=\"saved_model\"):\n",
    "    df = load_data_xlsx(file_path, sheet_name)\n",
    "    \n",
    "    df = df.dropna(subset=[\"Quality_Flag\"]).reset_index(drop=True)\n",
    "    df[\"Quality_Flag_Binary\"] = df[\"Quality_Flag\"].apply(lambda x: 1 if x in [1, '1.0'] else 0)\n",
    "    df[\"Combined_Text\"] = df.apply(combine_texts, axis=1)\n",
    "\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"Quality_Flag_Binary\"])\n",
    "    \n",
    "    train_texts = train_df[\"Combined_Text\"].fillna(\"missing_text\").astype(str).tolist()\n",
    "    train_labels = train_df[\"Quality_Flag_Binary\"].tolist()\n",
    "\n",
    "    # Load SBERT model and encode text\n",
    "    sbert_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    embeddings = sbert_model.encode(train_texts)\n",
    "\n",
    "    # Scale embeddings\n",
    "    scaler = StandardScaler()\n",
    "    embeddings_scaled = scaler.fit_transform(embeddings)\n",
    "\n",
    "    # Train classifier\n",
    "    clf = LogisticRegression(class_weight=\"balanced\", random_state=42, max_iter=1000, C=1.0)\n",
    "    clf.fit(embeddings_scaled, train_labels)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_texts = test_df[\"Combined_Text\"].fillna(\"missing_text\").astype(str).tolist()\n",
    "    test_labels = test_df[\"Quality_Flag_Binary\"].tolist()\n",
    "    \n",
    "    test_embeddings = sbert_model.encode(test_texts)\n",
    "    test_embeddings_scaled = scaler.transform(test_embeddings)\n",
    "    \n",
    "    predicted_labels = clf.predict(test_embeddings_scaled)\n",
    "    pred_probs = clf.predict_proba(test_embeddings_scaled)[:, 1]\n",
    "\n",
    "    # Save predictions to test_df\n",
    "    test_df[\"Predicted_Values\"] = predicted_labels\n",
    "    test_df[\"Prediction_Probability\"] = pred_probs\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "    print(f\"\\nðŸ”¹ **Test Accuracy: {accuracy:.4f}**\\n\")\n",
    "    print(\"ðŸ”¹ **Classification Report:**\")\n",
    "    print(classification_report(test_labels, predicted_labels, zero_division=0))\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(test_labels, predicted_labels)\n",
    "    print(\"\\nðŸ”¹ **Confusion Matrix:**\")\n",
    "    print(f\"   True Negative: {cm[0][0]}, False Positive: {cm[0][1]}\")\n",
    "    print(f\"   False Negative: {cm[1][0]}, True Positive: {cm[1][1]}\")\n",
    "\n",
    "    # Save test results to Excel\n",
    "    output_df = test_df[[\"Quality_Flag_Binary\", \"Predicted_Values\", \"Prediction_Probability\", \"Q16A_Likes\", \"Q16B_Dislikes\"]]\n",
    "    output_file = \"classifier_results_80_20_split.xlsx\"\n",
    "    output_df.to_excel(output_file, index=False)\n",
    "    print(f\"\\nðŸ”¹ **Test Results saved to '{output_file}'**\")\n",
    "\n",
    "    # Create directory for model saving\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "    # Save model components\n",
    "    joblib.dump(clf, f\"{model_path}/classifier.pkl\")\n",
    "    joblib.dump(scaler, f\"{model_path}/scaler.pkl\")\n",
    "    sbert_model.save(f\"{model_path}/sbert_model\")\n",
    "\n",
    "    print(f\"\\nðŸ”¹ Model saved to '{model_path}'\")\n",
    "\n",
    "# Load model and make predictions on new data\n",
    "def load_model_and_predict(input_file, output_file, model_path=\"saved_model\", sheet_name=\"Data Set with Labels Text\"):\n",
    "    df = load_data_xlsx(input_file, sheet_name)\n",
    "    \n",
    "    df[\"Combined_Text\"] = df.apply(combine_texts, axis=1)\n",
    "\n",
    "    # Load model components\n",
    "    clf = joblib.load(f\"{model_path}/classifier.pkl\")\n",
    "    scaler = joblib.load(f\"{model_path}/scaler.pkl\")\n",
    "    sbert_model = SentenceTransformer(f\"{model_path}/sbert_model\")\n",
    "\n",
    "    # Encode and scale text\n",
    "    texts = df[\"Combined_Text\"].fillna(\"missing_text\").astype(str).tolist()\n",
    "    embeddings = sbert_model.encode(texts)\n",
    "    embeddings_scaled = scaler.transform(embeddings)\n",
    "\n",
    "    # Make predictions\n",
    "    predicted_labels = clf.predict(embeddings_scaled)\n",
    "\n",
    "    # Save results to .xlsx\n",
    "    result_df = pd.DataFrame({\n",
    "        \"Predicted_Quality_Flag\": predicted_labels  # Output column\n",
    "    })\n",
    "    result_df.to_excel(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nðŸ”¹ Predictions saved to '{output_file}'\")\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    train_file = \"Final Data File_Training.xlsx\"\n",
    "    new_data_file = \"Final Data File_Test.xlsx\"\n",
    "    output_predictions_file = \"Predicted_Results.xlsx\"\n",
    "\n",
    "    # Train and save the model\n",
    "    train_and_save_model(train_file, \"Data Set with Labels Text\")\n",
    "\n",
    "    # Load model and make predictions on new dataset\n",
    "    load_model_and_predict(new_data_file, output_predictions_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 beer preference columns: ['Q18_1 What specific product that you are currently using would the shown product replace?\\n Please type in ONE specific brand or product per space provided.', 'Q18_2 What specific product that you are currently using would the shown concept replace?\\n Please type in ONE specific brand or product per space provided.', 'Q18_3 What specific product that you are currently using would the shown concept replace?\\n Please type in ONE specific brand or product per space provided.']\n",
      "\n",
      "ðŸ”¹ Class distribution in dataset:\n",
      "   - Good responses (0): 2119\n",
      "   - Bad responses (1): 180\n",
      "\n",
      "ðŸ”¹ Training set size: 1839\n",
      "ðŸ”¹ Test set size: 460\n",
      "\n",
      "ðŸ”¹ **Threshold Analysis:**\n",
      "   Threshold: 0.3\n",
      "   Accuracy: 0.7826\n",
      "   F1 Score (bad responses): 0.1667\n",
      "   True Negative: 350, False Positive: 74\n",
      "   False Negative: 26, True Positive: 10\n",
      "\n",
      "   Threshold: 0.5\n",
      "   Accuracy: 0.8217\n",
      "   F1 Score (bad responses): 0.1961\n",
      "   True Negative: 368, False Positive: 56\n",
      "   False Negative: 26, True Positive: 10\n",
      "\n",
      "   Threshold: 0.7\n",
      "   Accuracy: 0.8435\n",
      "   F1 Score (bad responses): 0.1628\n",
      "   True Negative: 381, False Positive: 43\n",
      "   False Negative: 29, True Positive: 7\n",
      "\n",
      "   Threshold: 0.9\n",
      "   Accuracy: 0.8717\n",
      "   F1 Score (bad responses): 0.1194\n",
      "   True Negative: 397, False Positive: 27\n",
      "   False Negative: 32, True Positive: 4\n",
      "\n",
      "ðŸ”¹ **Using best threshold: 0.5**\n",
      "\n",
      "ðŸ”¹ **Final Test Accuracy: 0.8217**\n",
      "\n",
      "ðŸ”¹ **Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       424\n",
      "           1       0.15      0.28      0.20        36\n",
      "\n",
      "    accuracy                           0.82       460\n",
      "   macro avg       0.54      0.57      0.55       460\n",
      "weighted avg       0.87      0.82      0.84       460\n",
      "\n",
      "ðŸ”¹ **Confusion Matrix:**\n",
      "   True Negative: 368, False Positive: 56\n",
      "   False Negative: 26, True Positive: 10\n",
      "\n",
      "ðŸ”¹ **Beer Preference Analysis**\n",
      "\n",
      "ðŸ“Š Most Common Products:\n",
      "\n",
      "   Q18_1 What specific product that you are currently using would the shown product replace?\n",
      " Please type in ONE specific brand or product per space provided.:\n",
      "     Bud light: 27 responses (10.8%)\n",
      "     Budweiser: 13 responses (5.2%)\n",
      "     Corona: 13 responses (5.2%)\n",
      "     Coors light: 8 responses (3.2%)\n",
      "     Coors: 8 responses (3.2%)\n",
      "\n",
      "   Q18_2 What specific product that you are currently using would the shown concept replace?\n",
      " Please type in ONE specific brand or product per space provided.:\n",
      "     Bud light: 26 responses (10.5%)\n",
      "     Budweiser: 18 responses (7.3%)\n",
      "     Coors: 9 responses (3.6%)\n",
      "     Heineken: 8 responses (3.2%)\n",
      "     Bud Light: 7 responses (2.8%)\n",
      "\n",
      "   Q18_3 What specific product that you are currently using would the shown concept replace?\n",
      " Please type in ONE specific brand or product per space provided.:\n",
      "     Heineken: 13 responses (5.3%)\n",
      "     Coors light: 12 responses (4.9%)\n",
      "     Coors: 12 responses (4.9%)\n",
      "     Corona: 10 responses (4.1%)\n",
      "     Budweiser: 8 responses (3.3%)\n",
      "\n",
      "ðŸ“Š Products by Quality Label:\n",
      "\n",
      "   Quality = 0 (Good):\n",
      "   - Q18_1 What specific product that you are currently using would the shown product replace?\n",
      " Please type in ONE specific brand or product per space provided.:\n",
      "     Bud light: 27 responses (11.6%)\n",
      "     Budweiser: 13 responses (5.6%)\n",
      "     Corona: 12 responses (5.2%)\n",
      "   - Q18_2 What specific product that you are currently using would the shown concept replace?\n",
      " Please type in ONE specific brand or product per space provided.:\n",
      "     Bud light: 22 responses (9.6%)\n",
      "     Budweiser: 18 responses (7.8%)\n",
      "     Coors: 9 responses (3.9%)\n",
      "   - Q18_3 What specific product that you are currently using would the shown concept replace?\n",
      " Please type in ONE specific brand or product per space provided.:\n",
      "     Coors: 12 responses (5.2%)\n",
      "     Coors light: 12 responses (5.2%)\n",
      "     Heineken: 12 responses (5.2%)\n",
      "\n",
      "   Quality = 1 (Bad):\n",
      "   - Q18_1 What specific product that you are currently using would the shown product replace?\n",
      " Please type in ONE specific brand or product per space provided.:\n",
      "     Michelob Ultra: 2 responses (11.1%)\n",
      "     Heineken: 2 responses (11.1%)\n",
      "     Mike hards: 1 responses (5.6%)\n",
      "   - Q18_2 What specific product that you are currently using would the shown concept replace?\n",
      " Please type in ONE specific brand or product per space provided.:\n",
      "     Bud light: 4 responses (22.2%)\n",
      "     Budlight: 2 responses (11.1%)\n",
      "     Busch: 2 responses (11.1%)\n",
      "   - Q18_3 What specific product that you are currently using would the shown concept replace?\n",
      " Please type in ONE specific brand or product per space provided.:\n",
      "     Light: 1 responses (5.9%)\n",
      "     Bud ligth: 1 responses (5.9%)\n",
      "     good: 1 responses (5.9%)\n",
      "\n",
      "ðŸ“Š Accuracy by Product Preference:\n",
      "\n",
      "   Q18_1 What specific product that you are currently using would the shown product replace?\n",
      " Please type in ONE specific brand or product per space provided.:\n",
      "     Bud light (n=27): Accuracy=0.8889, Bad Responses=0.0%\n",
      "     Budweiser (n=13): Accuracy=1.0000, Bad Responses=0.0%\n",
      "     Corona (n=13): Accuracy=0.8462, Bad Responses=7.7%\n",
      "\n",
      "   Q18_2 What specific product that you are currently using would the shown concept replace?\n",
      " Please type in ONE specific brand or product per space provided.:\n",
      "     Bud light (n=26): Accuracy=0.8077, Bad Responses=15.4%\n",
      "     Budweiser (n=18): Accuracy=0.7778, Bad Responses=0.0%\n",
      "\n",
      "   Q18_3 What specific product that you are currently using would the shown concept replace?\n",
      " Please type in ONE specific brand or product per space provided.:\n",
      "     Heineken (n=13): Accuracy=0.8462, Bad Responses=7.7%\n",
      "     Coors light (n=12): Accuracy=0.9167, Bad Responses=0.0%\n",
      "     Coors (n=12): Accuracy=0.6667, Bad Responses=0.0%\n",
      "     Corona (n=10): Accuracy=0.9000, Bad Responses=10.0%\n",
      "\n",
      "ðŸ”¹ **Test Results saved to 'classifier_results_with_beer_preferences.xlsx'**\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset and clean column names\n",
    "def load_data_xlsx(file_path, sheet_name=\"Data Set with Labels Text\"):\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    df.rename(columns={\n",
    "        \"Q16A. What is the most important thing you LIKE about the shown concept}?     This can include anything you would want kept for sure or aspects that might drive you to buy or try itâ€¦       Please type a detailed response in the space below\":\n",
    "            \"Q16A_Likes\",\n",
    "        \"Q16B. What is the most important thing you DISLIKE about the shown concept}?    This can include general concerns, annoyances, or any aspects of the product that need fixed for this to be more appealing to you...     Please type a detailed response in the space below.\":\n",
    "            \"Q16B_Dislikes\",\n",
    "        \"OE_Quality_Flag\": \"Quality_Flag\"\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Get beer preference columns (Q18_1, Q18_2, Q18_3)\n",
    "    beer_preference_columns = [col for col in df.columns if col.startswith('Q18_')]\n",
    "    print(f\"Found {len(beer_preference_columns)} beer preference columns: {beer_preference_columns}\")\n",
    "    \n",
    "    # Remove unnamed columns\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    \n",
    "    return df, beer_preference_columns\n",
    "\n",
    "# Prepare combined text feature\n",
    "def combine_texts(row):\n",
    "    # If any response is missing, fill with \"missing_text\"\n",
    "    text_a = str(row[\"Q16A_Likes\"]) if pd.notna(row[\"Q16A_Likes\"]) else \"missing_text\"\n",
    "    text_b = str(row[\"Q16B_Dislikes\"]) if pd.notna(row[\"Q16B_Dislikes\"]) else \"missing_text\"\n",
    "    return text_a + \" \" + text_b\n",
    "\n",
    "# Train classifier on combined text features using SBERT embeddings\n",
    "def train_classifier(texts, labels):\n",
    "    # Load SBERT model and encode text\n",
    "    sbert_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    embeddings = sbert_model.encode(texts)\n",
    "    \n",
    "    # Scale embeddings\n",
    "    scaler = StandardScaler()\n",
    "    embeddings_scaled = scaler.fit_transform(embeddings)\n",
    "    \n",
    "    # Train Logistic Regression with balanced class weights\n",
    "    clf = LogisticRegression(class_weight=\"balanced\", random_state=42, max_iter=1000, C=1.0)\n",
    "    clf.fit(embeddings_scaled, labels)\n",
    "    \n",
    "    return clf, scaler, sbert_model\n",
    "\n",
    "# Evaluate classifier on new texts\n",
    "def evaluate_classifier(clf, scaler, sbert_model, texts, threshold=0.5):\n",
    "    embeddings = sbert_model.encode(texts)\n",
    "    embeddings_scaled = scaler.transform(embeddings)\n",
    "    \n",
    "    # Get predicted probabilities (for class 1)\n",
    "    pred_probs = clf.predict_proba(embeddings_scaled)[:, 1]\n",
    "    predicted_labels = (pred_probs > threshold).astype(int)\n",
    "    return predicted_labels, pred_probs\n",
    "\n",
    "# Analyze beer preferences by prediction group\n",
    "def analyze_beer_preferences(df, beer_preference_columns):\n",
    "    results = {}\n",
    "    \n",
    "    # Skip analysis if no preference columns or if they're not in the dataframe\n",
    "    if not beer_preference_columns or not any(col in df.columns for col in beer_preference_columns):\n",
    "        print(\"\\nðŸ”¹ No beer preference columns found for analysis\")\n",
    "        return results\n",
    "    \n",
    "    # Overall analysis\n",
    "    print(\"\\nðŸ”¹ **Beer Preference Analysis**\")\n",
    "    \n",
    "    # Count the most common products for each preference column\n",
    "    print(\"\\nðŸ“Š Most Common Products:\")\n",
    "    for col in beer_preference_columns:\n",
    "        if col in df.columns:\n",
    "            # Get top 5 most common products\n",
    "            top_products = df[col].value_counts().head(5)\n",
    "            total_responses = len(df[col].dropna())\n",
    "            \n",
    "            print(f\"\\n   {col}:\")\n",
    "            for product, count in top_products.items():\n",
    "                if pd.notna(product) and product != '' and str(product).strip().lower() != 'none':\n",
    "                    pct = (count / total_responses) * 100\n",
    "                    print(f\"     {product}: {count} responses ({pct:.1f}%)\")\n",
    "    \n",
    "    # By True Label (Actual Quality)\n",
    "    print(\"\\nðŸ“Š Products by Quality Label:\")\n",
    "    for label in [0, 1]:\n",
    "        label_df = df[df[\"Quality_Flag_Binary\"] == label]\n",
    "        print(f\"\\n   Quality = {label} ({'Good' if label == 0 else 'Bad'}):\")\n",
    "        \n",
    "        for col in beer_preference_columns:\n",
    "            if col in df.columns:\n",
    "                # Get top 3 products for this group\n",
    "                top_products = label_df[col].value_counts().head(3)\n",
    "                total_responses = len(label_df[col].dropna())\n",
    "                \n",
    "                if total_responses > 0:\n",
    "                    print(f\"   - {col}:\")\n",
    "                    for product, count in top_products.items():\n",
    "                        if pd.notna(product) and product != '' and str(product).strip().lower() != 'none':\n",
    "                            pct = (count / total_responses) * 100\n",
    "                            print(f\"     {product}: {count} responses ({pct:.1f}%)\")\n",
    "    \n",
    "    # Accuracy by most common products\n",
    "    print(\"\\nðŸ“Š Accuracy by Product Preference:\")\n",
    "    for col in beer_preference_columns:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n   {col}:\")\n",
    "            # Get products with at least 10 responses\n",
    "            product_counts = df[col].value_counts()\n",
    "            common_products = product_counts[product_counts >= 10].index.tolist()\n",
    "            \n",
    "            for product in common_products:\n",
    "                if pd.notna(product) and product != '' and str(product).strip().lower() != 'none':\n",
    "                    product_df = df[df[col] == product]\n",
    "                    if len(product_df) > 0:\n",
    "                        acc = accuracy_score(product_df[\"Quality_Flag_Binary\"], product_df[\"Predicted_Values\"])\n",
    "                        # Calculate percentage of bad responses for this product\n",
    "                        bad_pct = (product_df[\"Quality_Flag_Binary\"].sum() / len(product_df)) * 100\n",
    "                        print(f\"     {product} (n={len(product_df)}): Accuracy={acc:.4f}, Bad Responses={bad_pct:.1f}%\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Main function with 80/20 train/test split\n",
    "def main(file_path, sheet_name):\n",
    "    df, beer_preference_columns = load_data_xlsx(file_path, sheet_name)\n",
    "    \n",
    "    # Drop rows with missing Quality_Flag and reset index\n",
    "    df = df.dropna(subset=[\"Quality_Flag\"]).reset_index(drop=True)\n",
    "    \n",
    "    # Convert Quality_Flag to binary labels: assume 1 or '1.0' as Bad, else Good (0)\n",
    "    df[\"Quality_Flag_Binary\"] = df[\"Quality_Flag\"].apply(lambda x: 1 if x in [1, '1.0'] else 0)\n",
    "    \n",
    "    # Combine Q16A and Q16B responses into one feature\n",
    "    df[\"Combined_Text\"] = df.apply(combine_texts, axis=1)\n",
    "    \n",
    "    # Count class distribution\n",
    "    class_counts = df[\"Quality_Flag_Binary\"].value_counts()\n",
    "    print(f\"\\nðŸ”¹ Class distribution in dataset:\")\n",
    "    print(f\"   - Good responses (0): {class_counts.get(0, 0)}\")\n",
    "    print(f\"   - Bad responses (1): {class_counts.get(1, 0)}\")\n",
    "    \n",
    "    # Split dataset into 80% training and 20% testing\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        stratify=df[\"Quality_Flag_Binary\"]  # Maintain class distribution\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nðŸ”¹ Training set size: {len(train_df)}\")\n",
    "    print(f\"ðŸ”¹ Test set size: {len(test_df)}\")\n",
    "    \n",
    "    # Train classifier on combined text from the training set\n",
    "    train_texts = train_df[\"Combined_Text\"].fillna(\"missing_text\").astype(str).tolist()\n",
    "    train_labels = train_df[\"Quality_Flag_Binary\"].tolist()\n",
    "    clf, scaler, sbert_model = train_classifier(train_texts, train_labels)\n",
    "    \n",
    "    # Evaluate on test set with different thresholds\n",
    "    thresholds = [0.3, 0.5, 0.7, 0.9]\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0\n",
    "    \n",
    "    print(\"\\nðŸ”¹ **Threshold Analysis:**\")\n",
    "    for threshold in thresholds:\n",
    "        test_texts = test_df[\"Combined_Text\"].fillna(\"missing_text\").astype(str).tolist()\n",
    "        predicted_labels, pred_probs = evaluate_classifier(clf, scaler, sbert_model, test_texts, threshold=threshold)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        test_df[\"Predicted_Values\"] = predicted_labels\n",
    "        test_df[\"Prediction_Probability\"] = pred_probs\n",
    "        \n",
    "        # Print evaluation metrics\n",
    "        accuracy = accuracy_score(test_df[\"Quality_Flag_Binary\"], test_df[\"Predicted_Values\"])\n",
    "        report = classification_report(test_df[\"Quality_Flag_Binary\"], test_df[\"Predicted_Values\"], \n",
    "                                      zero_division=0, output_dict=True)\n",
    "        \n",
    "        # Get F1 score for the positive class (bad responses) if it exists in the report\n",
    "        f1_score = report.get('1', {}).get('f1-score', 0)\n",
    "        \n",
    "        if f1_score > best_f1:\n",
    "            best_f1 = f1_score\n",
    "            best_threshold = threshold\n",
    "        \n",
    "        print(f\"\\n   Threshold: {threshold}\")\n",
    "        print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"   F1 Score (bad responses): {f1_score:.4f}\")\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(test_df[\"Quality_Flag_Binary\"], test_df[\"Predicted_Values\"])\n",
    "        print(f\"   True Negative: {cm[0][0]}, False Positive: {cm[0][1]}\")\n",
    "        print(f\"   False Negative: {cm[1][0]}, True Positive: {cm[1][1]}\")\n",
    "    \n",
    "    # Use the best threshold for final evaluation\n",
    "    print(f\"\\nðŸ”¹ **Using best threshold: {best_threshold}**\")\n",
    "    test_texts = test_df[\"Combined_Text\"].fillna(\"missing_text\").astype(str).tolist()\n",
    "    predicted_labels, pred_probs = evaluate_classifier(clf, scaler, sbert_model, test_texts, threshold=best_threshold)\n",
    "    \n",
    "    # Save predictions to test_df\n",
    "    test_df[\"Predicted_Values\"] = predicted_labels\n",
    "    test_df[\"Prediction_Probability\"] = pred_probs\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    accuracy = accuracy_score(test_df[\"Quality_Flag_Binary\"], test_df[\"Predicted_Values\"])\n",
    "    print(f\"\\nðŸ”¹ **Final Test Accuracy: {accuracy:.4f}**\\n\")\n",
    "    print(\"ðŸ”¹ **Classification Report:**\")\n",
    "    print(classification_report(test_df[\"Quality_Flag_Binary\"], test_df[\"Predicted_Values\"], zero_division=0))\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(test_df[\"Quality_Flag_Binary\"], test_df[\"Predicted_Values\"])\n",
    "    print(\"\\nðŸ”¹ **Confusion Matrix:**\")\n",
    "    print(f\"   True Negative: {cm[0][0]}, False Positive: {cm[0][1]}\")\n",
    "    print(f\"   False Negative: {cm[1][0]}, True Positive: {cm[1][1]}\")\n",
    "    \n",
    "    # Analyze beer preferences\n",
    "    analyze_beer_preferences(test_df, beer_preference_columns)\n",
    "    \n",
    "    # Columns to save\n",
    "    output_columns = [\"Quality_Flag_Binary\", \"Predicted_Values\", \"Prediction_Probability\", \n",
    "                      \"Q16A_Likes\", \"Q16B_Dislikes\"]\n",
    "    \n",
    "    # Add beer preference columns to output\n",
    "    for col in beer_preference_columns:\n",
    "        if col in test_df.columns:\n",
    "            output_columns.append(col)\n",
    "    \n",
    "    # Save test results to Excel with detailed analysis\n",
    "    output_df = test_df[output_columns]\n",
    "    output_file = \"classifier_results_with_beer_preferences.xlsx\"\n",
    "    output_df.to_excel(output_file, index=False)\n",
    "    print(f\"\\nðŸ”¹ **Test Results saved to '{output_file}'**\")\n",
    "    \n",
    "    # Create additional sheet with product-specific analysis\n",
    "    if beer_preference_columns:\n",
    "        with pd.ExcelWriter(output_file, engine='openpyxl', mode='a') as writer:\n",
    "            # Top products summary\n",
    "            product_summary = []\n",
    "            for col in beer_preference_columns:\n",
    "                if col in df.columns:\n",
    "                    top_prods = df[col].value_counts().head(10).reset_index()\n",
    "                    top_prods.columns = ['Product', 'Count']\n",
    "                    top_prods['Column'] = col\n",
    "                    product_summary.append(top_prods)\n",
    "            \n",
    "            if product_summary:\n",
    "                pd.concat(product_summary).to_excel(writer, sheet_name='Top Products', index=False)\n",
    "            \n",
    "            # Product accuracy summary\n",
    "            product_accuracy = []\n",
    "            for col in beer_preference_columns:\n",
    "                if col in test_df.columns:\n",
    "                    product_counts = test_df[col].value_counts()\n",
    "                    common_products = product_counts[product_counts >= 5].index.tolist()\n",
    "                    \n",
    "                    for product in common_products:\n",
    "                        if pd.notna(product) and product != '' and str(product).strip().lower() != 'none':\n",
    "                            product_df = test_df[test_df[col] == product]\n",
    "                            if len(product_df) > 0:\n",
    "                                acc = accuracy_score(product_df[\"Quality_Flag_Binary\"], product_df[\"Predicted_Values\"])\n",
    "                                bad_pct = (product_df[\"Quality_Flag_Binary\"].sum() / len(product_df)) * 100\n",
    "                                \n",
    "                                product_accuracy.append({\n",
    "                                    'Column': col,\n",
    "                                    'Product': product,\n",
    "                                    'Count': len(product_df),\n",
    "                                    'Accuracy': acc,\n",
    "                                    'Bad_Response_Pct': bad_pct\n",
    "                                })\n",
    "            \n",
    "            if product_accuracy:\n",
    "                pd.DataFrame(product_accuracy).to_excel(writer, sheet_name='Product Accuracy', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    xlsx_file = \"Final Data File_Training.xlsx\"\n",
    "    sheet_name = \"Data Set with Labels Text\"\n",
    "    main(xlsx_file, sheet_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
